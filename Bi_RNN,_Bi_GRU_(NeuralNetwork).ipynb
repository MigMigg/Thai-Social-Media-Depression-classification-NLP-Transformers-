{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp\n",
        "!pip install attacut"
      ],
      "metadata": {
        "id": "yjSgSzFaxS6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,  ConfusionMatrixDisplay\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, GRU"
      ],
      "metadata": {
        "id": "RPRUggzKxXZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and preprocess the data"
      ],
      "metadata": {
        "id": "juIoVGO32Xr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Depression_Dataset.csv')"
      ],
      "metadata": {
        "id": "oPHOFxKgxw6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "id": "ewcspuhgydEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.text\n",
        "y = data.label"
      ],
      "metadata": {
        "id": "yLSWn6TiyZAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize Thai text"
      ],
      "metadata": {
        "id": "vjqqpmbK2xcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "  return word_tokenize(sentence, engine=\"attacut\")"
      ],
      "metadata": {
        "id": "Mg1AggLPx2_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_list = [tokenize(sent) for sent in X ]\n",
        "tokenize_list"
      ],
      "metadata": {
        "id": "AR93oOAjyhip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = [' '.join(text) for text in tokenize_list]\n",
        "\n",
        "# สร้าง tokenizer และ fit\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tokenized_texts)\n",
        "\n",
        "#แปลงเป็นลำดับตัวเลข (sequence)\n",
        "sequences = tokenizer.texts_to_sequences(tokenized_texts)\n",
        "maxlen = max([len(s) for s in sequences])\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "print(\"Word Index:\", tokenizer.word_index)\n",
        "print(\"Sequences:\", sequences)\n",
        "print(\"Padded Sequences:\", padded_sequences)\n",
        "print(\"Max length =\", maxlen)\n",
        "print(\"Padded Seq shape =\",padded_sequences.shape)"
      ],
      "metadata": {
        "id": "fwa8xxmS_OFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply train-test split"
      ],
      "metadata": {
        "id": "W3gg0m_3UWuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test , y_train, y_test = train_test_split(padded_sequences, y, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "_KpLbyb53FK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val , y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "Md5ZUCM-BAoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) +1"
      ],
      "metadata": {
        "id": "NR5nPFGt_vEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bidirectional RNN"
      ],
      "metadata": {
        "id": "YB7zyQZm4v_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=300, input_length=maxlen),\n",
        "    Bidirectional(SimpleRNN(units=16, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(SimpleRNN(units=32, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(SimpleRNN(units=64, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(SimpleRNN(units=128, activation = 'relu')),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FllCr8rt4sPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.002), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FuSqO9Q-_pVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train , y_train, epochs= 3, batch_size = 512, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "id": "tWLFd4Yj_mFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history.keys()\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(hist.history[\"loss\"],'cornflowerblue', marker='.', label=\"train\")\n",
        "ax.plot(hist.history[\"val_loss\"],'orange', marker='.', label=\"val\")\n",
        "ax.set(xlabel='epoch', ylabel = 'loss', title='Loss')\n",
        "ax.set_xticks([1] + list(ax.get_xticks()[ax.get_xticks() > 1]))\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(hist.history[\"accuracy\"],'cornflowerblue', marker='.', label=\"train\")\n",
        "ax.plot(hist.history[\"val_accuracy\"],'orange', marker='.', label=\"val\")\n",
        "ax.set(xlabel='epoch', ylabel = 'accuracy', title='Accuracy')\n",
        "ax.set_xticks([1] + list(ax.get_xticks()[ax.get_xticks() > 1]))\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YCcy3n8IJTrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "SxlU3lUXIqaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "print(\"Bi-RNN Accuracy on test data:\", round(accuracy_score(y_test, y_pred),2))"
      ],
      "metadata": {
        "id": "B6nuTJC9IGfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\",\"Negative\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FjXqpG_DIpku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf = classification_report(y_test, y_pred)\n",
        "print(cf)"
      ],
      "metadata": {
        "id": "1khH8viTIUBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bidirectioanl GRU"
      ],
      "metadata": {
        "id": "PSLwIR2tTbv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "model2 = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=300, input_length=maxlen),\n",
        "    Bidirectional(GRU(units=16, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(GRU(units=32, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(GRU(units=64, activation = 'relu', return_sequences=True)),\n",
        "    Bidirectional(GRU(units=128, activation = 'relu')),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "CSZP0jy7QrCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.0025), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PyIz-7tUQ0H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist2 = model2.fit(x_train , y_train, epochs= 3, batch_size = 512, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "id": "Htnt0gUcQ9mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist2.history.keys()\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(hist2.history[\"loss\"],'cornflowerblue', marker='.', label=\"train\")\n",
        "ax.plot(hist2.history[\"val_loss\"],'orange', marker='.', label=\"val\")\n",
        "ax.set(xlabel='epoch', ylabel = 'loss', title='Loss')\n",
        "ax.set_xticks([1] + list(ax.get_xticks()[ax.get_xticks() > 1]))\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(hist2.history[\"accuracy\"],'cornflowerblue', marker='.', label=\"train\")\n",
        "ax.plot(hist2.history[\"val_accuracy\"],'orange', marker='.', label=\"val\")\n",
        "ax.set(xlabel='epoch', ylabel = 'accuracy', title='Accuracy')\n",
        "ax.set_xticks([1] + list(ax.get_xticks()[ax.get_xticks() > 1]))\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i-l2pW6tUrW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model2.predict(x_test)"
      ],
      "metadata": {
        "id": "FvpfxccbV2m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "print(\"Bi-GRU Accuracy on test data:\", round(accuracy_score(y_test, y_pred),2))"
      ],
      "metadata": {
        "id": "h43iyo5MXSk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\",\"Negative\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TRyXPXxwXZK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf = classification_report(y_test, y_pred)\n",
        "print(cf)"
      ],
      "metadata": {
        "id": "9aam_SIsXZes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test With New Sample"
      ],
      "metadata": {
        "id": "d8cUWGMxlUzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict custom sentences\n",
        "sample_sentences = [ \"ช่วงนี้นอนไม่หลับ เบื่ออาหาร รู้สึกหมดแรงและไม่อยากคุยกับใครเลย\",\n",
        "    \"วันนี้อารมณ์ดีมาก ไปออกกำลังกายและทำงานบ้านเรียบร้อย\",\n",
        "    \"รู้สึกกังวลบ่อย ๆ สมาธิไม่ค่อยอยู่กับเนื้อกับตัว แต่พยายามทำงานต่อ\",\n",
        "    \"เมื่อคืนหัวเราะกับเพื่อน ๆ สนุกดี ไม่มีอะไรให้เครียดเท่าไหร่\",\n",
        "    \"บางวันไม่อยากลุกจากเตียงเลย เหนื่อยล้าแบบไม่มีเหตุผล\",]\n",
        "X_new = [ tokenize(x) for x in sample_sentences]\n",
        "x_new_tokenize = []\n",
        "for x in X_new :\n",
        "  new_sent = []\n",
        "  for token in x :\n",
        "    if token in tokenizer.word_index.keys() :\n",
        "      new_sent.append(tokenizer.word_index[token])\n",
        "    else :\n",
        "      new_sent.append(0)\n",
        "  x_new_tokenize.append(new_sent)\n",
        "x_new_tokenize_padded = pad_sequences(x_new_tokenize, padding='post', maxlen = maxlen)\n",
        "y_pred_sample1 = model.predict(x_new_tokenize_padded)\n",
        "y_pred_sample2 = model2.predict(x_new_tokenize_padded)"
      ],
      "metadata": {
        "id": "a3ekNbPgYpEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sample_sentences)) :\n",
        "  print(sample_sentences[i],\":\",end=' ')\n",
        "  if (y_pred_sample1[i] >= 0.5) :\n",
        "    print(\"Bi-RNN -> Postivie\",end = ', ')\n",
        "  else :\n",
        "    print(\"Bi-RNN -> Negative\",end = ', ')\n",
        "  if (y_pred_sample2[i] >= 0.5) :\n",
        "    print(\"Bi-GRU -> Postivie\")\n",
        "  else :\n",
        "    print(\"Bi-GRU -> Negative\")\n"
      ],
      "metadata": {
        "id": "NOqKnLTDYlAi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}