{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNSVbTFdOGfV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset and Pre-process data"
      ],
      "metadata": {
        "id": "Taq61Bj6kbAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Depression_Dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Pek_fEzzQ0ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "G67-7CRgRNZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "id": "Q8u84BqFa4dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "yDZPPDPvbIHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Tokenizer from huggingface"
      ],
      "metadata": {
        "id": "ZHDAomHjkvMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased')"
      ],
      "metadata": {
        "id": "59WUK0UOvsom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "4jSNn4ofy5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Valdation Test Split"
      ],
      "metadata": {
        "id": "KqYo_ge2k8Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "train_valid_test = dataset.train_test_split(test_size=0.3, seed=42)\n",
        "train_valid = train_valid_test['train']\n",
        "test_dataset = train_valid_test['test']\n",
        "\n",
        "train_valid_split = train_valid.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_valid_split['train']\n",
        "valid_dataset = train_valid_split['test']\n",
        "\n",
        "from datasets import DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': valid_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "tokenized_dataset = dataset_dict.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "id": "s53YMIwWzEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Data Collator"
      ],
      "metadata": {
        "id": "uPoMukZRlRrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "b8qTzgQtzJEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pretrained Model for Sequence Classification"
      ],
      "metadata": {
        "id": "3sGx_scWlVHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "YXH1KWCKzwr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "mwNHsZv6Wkyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "f1_metric = evaluate.load(\"f1\")"
      ],
      "metadata": {
        "id": "qveWe2ME4vID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels)\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy[\"accuracy\"],\n",
        "        \"precision\": precision[\"precision\"],\n",
        "        \"recall\": recall[\"recall\"],\n",
        "        \"f1\": f1[\"f1\"]\n",
        "\n",
        "    }\n"
      ],
      "metadata": {
        "id": "g7RKuO5l42Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    from transformers import AutoModelForSequenceClassification\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"airesearch/wangchanberta-base-att-spm-uncased\",\n",
        "        num_labels=2\n",
        "    )"
      ],
      "metadata": {
        "id": "xVeF3NuJJ7HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training Arguments & Initialize Trainer"
      ],
      "metadata": {
        "id": "YaM01n5YmIvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    seed=42,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "M89_t7sa0MGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "itBAP5p-mPhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model(\"./final_model\")"
      ],
      "metadata": {
        "id": "VNTpzBEPgmmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "MjL2J9XDmTkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = trainer.evaluate()\n",
        "val_metrics"
      ],
      "metadata": {
        "id": "bXHLV42W46OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
        "test_metrics"
      ],
      "metadata": {
        "id": "CFoTj6Fx-62V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "VSsT5uhfmXYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_output = trainer.predict(tokenized_dataset['test'])\n",
        "\n",
        "y_pred = np.argmax(test_output.predictions, axis=1)\n",
        "y_true = test_output.label_ids\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Neg\", \"Pos\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Neg\", \"Pos\"], digits=4))\n"
      ],
      "metadata": {
        "id": "g3H1mD8AJlpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loss & Accuracy"
      ],
      "metadata": {
        "id": "4JuCToUtmefy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_steps = [], []\n",
        "eval_loss, eval_accuracy, eval_steps = [], [], []\n",
        "\n",
        "for log in trainer.state.log_history:\n",
        "    if \"loss\" in log and \"eval_loss\" not in log:\n",
        "        train_loss.append(log[\"loss\"])\n",
        "        train_steps.append(log[\"step\"])\n",
        "    if \"eval_loss\" in log:\n",
        "        eval_loss.append(log[\"eval_loss\"])\n",
        "        eval_steps.append(log[\"step\"])\n",
        "        if \"eval_accuracy\" in log:\n",
        "            eval_accuracy.append(log[\"eval_accuracy\"])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_steps, train_loss, label=\"Train Loss\")\n",
        "plt.plot(eval_steps, eval_loss, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "if eval_accuracy:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(eval_steps, eval_accuracy, marker=\"o\", label=\"Validation Accuracy\", color=\"green\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Validation Accuracy\")\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "04mWT28g0Zu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Model Generalization"
      ],
      "metadata": {
        "id": "kwooVnDRmmKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"ไม่อยากตื่นเจอวันพรุ่งนี้\",\n",
        "    \"ฉันกำลังรักษาโรคซึมเศร้า\",\n",
        "    \"วันนี้รู้สึกดีมาก มีความสุข\",\n",
        "    \"ไม่มีแรงทำอะไรเลย เหนื่อยจนทนไม่ไหว\",\n",
        "    \"ชีวิตนี้ไม่มีความหมาย\",\n",
        "    \"เราหวังจะมีเจ้าชายออกมาจากตะเกียงหรอ\",\n",
        "    \"หลังจากได้รับการรักษามาสักระยะ\",\n",
        "]\n",
        "\n",
        "inputs = tokenizer(\n",
        "    texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "import torch\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "    preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "for i, text in enumerate(texts):\n",
        "    label = preds[i].item()\n",
        "    confidence = probs[i][label].item()\n",
        "    result = \"เป็นโรคซึมเศร้า\" if label == 1 else \"ไม่เป็นโรคซึมเศร้า\"\n",
        "    print(f\"'{text}' → {result} (ความมั่นใจ = {confidence:.2f})\")\n"
      ],
      "metadata": {
        "id": "VNmBqOTwgUO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTENHdFFqYz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}